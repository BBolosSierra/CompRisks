---
title: "Discrimination measures"
output: html_document
date: "2024-10-19"
---


## Time to event metrics

The problem with the R packages to calculate metrics is that they are dependent on R packages to calculate survival. 


```{r}
library(survival)
library(riskRegression)
library(prodlim)
library(ggplot2)
library(geepack)
library(dplyr)
library(rsample)
```

### Download data 

Github: https://github.com/survival-lumc/ValidationCompRisks/tree/main/Data

Paper: doi https://doi.org/10.1136/bmj-2021-069249

"The dataset is part of FOCUS cohort (van Geloven N, Swanson SA, Ramspek CL, et al. 2020). In this retrospective cohort, all consecutive patients aged 65 years or older with breast cancer diagnosed in the South-West region of the Netherlands in the years 1997-2004 were included. The registry contains information on patient-characteristics including tumor characteristics, treatment and disease recurrence. 
Follow-up data on patient survival (maximal 5 years) was obtained by linkage with the municipal population registries. We applied the following inclusion criteria (same inclusion criteria that were used in the validation cohort): patients with primary breast cancer who received primary breast surgery, and received no previous neoadjuvant treatment. We used a random subset of 1000 patients to allow Open Access data sharing. Out of these 1000 patients in the development set, 135 developed breast cancer recurrence and 204 had a non-recurrence death within the five years follow up (cumulative incidence curve in Supplementary Figure 1).
Except for the higher age inclusion criterion in the validation cohort, patients were rather similar on the listed characteristics in the development and validation cohorts," called rdata and vdata in Github respectively. 

```{r}
# Create a directory to store downloaded data
if (!dir.exists("LumcData")) {
  dir.create("LumcData")
}

# Fix paths
file_urls <- c(
  "https://raw.githubusercontent.com/survival-lumc/ValidationCompRisks/main/Data/rdata.rds",
  "https://raw.githubusercontent.com/survival-lumc/ValidationCompRisks/main/Data/vdata.rds"
)

# Download files
for (url in file_urls) {
  file_name <- basename(url) # Extract the file name from the URL
  if (!file.exists("LumcData/rdata.rds") || !file.exists("LumcData/vdata.rds")) {
    message("Downloading data")
    download.file(url, destfile = file.path("LumcData", file_name), method = "libcurl")
  } else {
    message("Data is already downloaded")
  }
}

# Check if the files are downloaded
list.files("LumcData")


```


We will follow: https://www.bmj.com/content/377/bmj-2021-069249 and https://github.com/survival-lumc/ValidationCompRisks/blob/main/Prediction_CSC.md


```{r}
# Import data ------------------
rdata <- readRDS("LumcData/rdata.rds")
vdata <- readRDS("LumcData/vdata.rds")

rdata$hr_status <- relevel(rdata$hr_status, ref = "ER and/or PR +")
vdata$hr_status <- relevel(vdata$hr_status, ref = "ER and/or PR +")

```

```{r}
rdata$status <- rdata$status_num
vdata$status <- vdata$status_num
```


Each model will have a different summary and it is relevant to identify key elements that are needed to calculate the metrics. 

We will follow: https://www.bmj.com/content/377/bmj-2021-069249


```{r}

fit_csh <- riskRegression::CSC(Hist(time, status) ~
age + size +
  ncat + hr_status,
data = rdata
)

# useful objects
primary_event <- 1 # Set to 2 if cause 2 was of interest
horizon <- 5 # Set time horizon for prediction (here 5 years)

# Predicted risk estimation
pred <- riskRegression::predictRisk(fit_csh,
  cause = primary_event,
  times = horizon,
  newdata = vdata
)

```

```{r message=FALSE}
# C-index
# Development set (Apparent validation)

C_rdata <- pec::cindex(
  object = fit_csh,
  formula = Hist(time, status_num) ~ 1,
  cause = primary_event,
  eval.times = horizon,
  data = rdata
)$AppCindex$CauseSpecificCox

# Validation set
C_vdata <- pec::cindex(
  object = fit_csh,
  formula = Hist(time, status_num) ~ 1,
  cause = primary_event,
  eval.times = horizon,
  data = vdata
)$AppCindex$CauseSpecificCox


# Bootstraping C-index to calculate the bootstrap percentile confidence intervals

B <- 100
set.seed(1234)
rboot <- rsample::bootstraps(rdata, times = B) # development - bootstrap
vboot <- rsample::bootstraps(vdata, times = B) # validation - bootstrap

C_boot <- function(split) {
  pec::cindex(
    object = fit_csh,
    formula = Hist(time, status_num) ~ 1,
    cause = primary_event,
    eval.times = horizon,
    data = analysis(split)
  )$AppCindex$CauseSpecificCox
}

# Run time-dependent AUC in the bootstrapped development and validation data
# to calculate the non-parametric CI through percentile bootstrap
rboot <- rboot |> mutate(
  C_rboot = purrr::map_dbl(splits, C_boot),
)
vboot <- vboot |> mutate(
  C_vboot = purrr::map_dbl(splits, C_boot),
)


# Time-dependent AUC ---------

# Development data
score_rdata <- Score(
  list("csh_development" = fit_csh),
  formula = Hist(time, status_num) ~ 1,
  cens.model = "km",
  data = rdata,
  conf.int = TRUE,
  times = horizon,
  metrics = c("auc"),
  cause = primary_event,
  plots = "calibration"
)

# Validation data
score_vdata <- Score(
  list("csh_validation" = fit_csh),
  formula = Hist(time, status_num) ~ 1,
  cens.model = "km",
  data = vdata,
  conf.int = TRUE,
  times = horizon,
  metrics = c("auc"),
  cause = primary_event,
  plots = "calibration"
)
```


```{r}
C_vdata
```


## Concodance index

The c index ranges from 0.5 (no discriminating ability) to 1.0 (perfect ability to discriminate between patients with different outcomes).

Time-dependent Concordance Index (C(t)) for competing risks and focuses on comparing the relative ordering of risks assigned by the model for individuals experiencing the event of interest at or before a specific time tau.

### Custom function 

A and B account for the number of risk order pairs.
  
A == risk ordering of patients, small time means patient 'i' at higher risk than patient 'j' experiencing event of interest 
  
B == risk ordering of patients, large time for patient 'i' means lower risk than patient 'j' if not experienced the event of interest.
  
Q == the risk ordering of the subjects, i.e., is subject i assigned a higher risk by the model than the subject j, for event Ek until time t.
  
N_t == number of subjects with survival time < time point and experience event of interest
  
$$C_k(\tau) = \frac{\sum_{i=1}^N \sum_{j=1}^N (A_{ij} + B_{ij}) \cdot Q_{ij} \cdot N_i^k(\tau)}{\sum_{i=1}^N \sum_{j=1}^N (A_{ij} + B_{ij}) \cdot N_i^k(\tau)}$$


```{r}
source("CompRisksMetrics/ConcordanceIndex.R") 
```

```{r}
CIndexCRisks(predictions=pred,
                          time = vdata$time,
                          cens.code = 0,
                          status=vdata$status,
                          cause= primary_event, 
                          tau=horizon,
                          method = "cifs")
```


```{r}
C_vdata
```

We get a different result. Why??


In pec: 

https://github.com/cran/pec/blob/master/src/cindex.c

With the defaults (tiedPredictionsIn = TRUE, tiedOutcomeIn = TRUE, tiedMatchIn = TRUE):

1. Pairs with identical predictions are included as default, tiedPredictionsIn = TRUE. If tiedPredictionsIn = FALSE, the pairs with identical predictions are then excluded. Unless their event times are tied AND tiedMatchId is set to TRUE, in that case, they are concordant.

2. Pairs with identical uncensored event times are included as default, tiedOutcomeIn = TRUE. If tiedOutcomeIn is set to FALSE, they are excluded unless their predictions are tied AND tiedMatchIn is set to TRUE, in that case, they will be considered concordant. 


##### In detail

$Y[i] \leq Y[j]$: Subject i  has an earlier or equal event time.

\text{status}[i] = 1: Subject i  is uncensored.
w_i > 0 \quad \text{and} \quad w_j > 0 : Pair weights are positive.

\text{pred}[i] < \text{pred}[j] : Predicted risks are concordant.

\textbf{Tied Predictions}: \text{pred}[i] = \text{pred}[j] : Half concordance if \texttt{tiedpredIn = TRUE}.

\textbf{Tied Outcomes}: Y[i] = Y[j] : Pair is included if \texttt{tiedoutcomeIn = TRUE}.

\textbf{Fully Tied Pairs}:
$Y[i] = Y[j]$ \quad \text{and} \quad \text{pred}[i] = \text{pred}[j]: Fully concordant if \texttt{tiedmatchIn = TRUE}.


In pec censoring weights are also included:

```{r}

tmp <- vdata
tmp$censor.status <- ifelse(tmp$status %in% c(1, 2), 1, 0)

tmp <- tmp[order(tmp$time),]

weight.i <- pec::ipcw(formula=Surv(time,censor.status)~1,
                 data=tmp,
                 method="marginal",
                 times=unique(tmp$time),
                 subjectTimes=tmp$time, 
                 what = "IPCW.subjectTimes")$IPCW.subjectTimes
weight.j <- pec::ipcw(formula=Surv(time,censor.status)~1,
                 data=tmp,
                 method="marginal",
                 times=unique(tmp$time),
                 subjectTimes=tmp$time,
                 subjectTimesLag=0,
                 what="IPCW.times")$IPCW.times


```

```{r}
length(weight.i)
length(weight.j)
```



### Custom functions for ipcw

```{r}
## Calculate the censoring probabilities
## Using prodlim
## Controlling for competing risks
## No covariates in this function
test.censor.prob.KM <- function(time, status, cens.code){
  tmp <- data.frame(time=time, status = status)
  # Sets the value in status equal to cens.code to 0, the rest to 1
  # Controlling for competing risks in censoring status
  tmp$censor.status <- ifelse(status == cens.code, 0, 1) # Not handled in riskRegression with cmprsks
  # Order it by time
  #tmp <- tmp[order(tmp$time),]
  # Fit prodlim, reversed non-parametric survival KM
  # Switches the censoring status to estimate censoring distribution
  fit = prodlim::prodlim(formula=Surv(time,censor.status)~1,
                         data=tmp,
                         reverse=TRUE)
  # Predict weights at specific times
  weights = stats::predict(fit,
                           times=unique(tmp$time), 
                           level.chaos=1,
                           mode="matrix",
                           type="surv")
  
  out <- data.frame(cbind(unique.times=unique(tmp$time), ipcw.times=weights))
  
  return(out)
}

## Calculate the censoring probabilities
## Using prodlim
## Controlling for competing risks
## No covariates in this function
test.censor.prob.KM.individual <- function(time, status, cens.code, predictions, lag){
  tmp <- data.frame(time=time, status=status, predictions = predictions)
  # Sets the value in status equal to cens.code to 0, the rest to 1
  # Controlling for competing risks in censoring status
  tmp$censor.status <- ifelse(status == cens.code, 0, 1) # Not handled in riskRegression with cmprsks
  # We need to consider that the prodlim needs ordering 
  tmp <- tmp[order(tmp$time),]
  # Fit prodlim, reversed non-parametric survival KM
  # Switches the censoring status to estimate censoring distribution
  fit = prodlim::prodlim(formula=Surv(time,censor.status)~1,
                         data=tmp,
                         reverse=TRUE)
  # Predict weights at subject specific times
  ipcw.subject.times = prodlim::predictSurvIndividual(fit,lag=lag)
  
  tmp$ipcw.subject.times <- ipcw.subject.times
  
  return(tmp)
}
```

```{r}
# Censoring probabilities at subjects times
cwi <- test.censor.prob.KM.individual(time=vdata$time, status=vdata$status, cens.code=0, predictions=pred, lag=1)
dim(cwi)
```

```{r}
# Censor probabilities at specific time points
cwj <- test.censor.prob.KM(time=vdata$time, status=vdata$status, cens.code=0)
dim(cwj)
```


Are we getting the same results?

```{r}
identical(cwi$ipcw.subject.times, weight.i) 
```

```{r}
identical(cwj$ipcw.times, weight.j)
```


### Including ties and IPCW

Therefore we need to include IPCW and similar logic for ties:


```{r}
CIndexCRisks2 <- function(predictions, 
                         time,
                         cens.code, 
                         status, 
                         cause, 
                         tau,
                         ipcw,
                         method=c("survival","cifs")){
  
  method = match.arg(method)
  
  censor.status <- ifelse(status == cens.code, 0, 1)
  
  
  if( method=="survival" ){ predictions=1-predictions; }
  
  n = length(predictions)
  A = matrix(0, nrow=n, ncol=n)
  B = matrix(0, nrow=n, ncol=n)
  Q = matrix(0, nrow=n, ncol=n) 
  N_t = matrix(0, nrow=n, ncol=n)
  Num_mat = matrix(0, nrow=n, ncol=n)
  Den_mat = matrix(0, nrow=n, ncol=n)
  
  Num=0
  Den=0
  for (i in  1:n){
    # Identify usable pairs based on time
    A[i, which(time[i] <= time)] = 1 
    B[i, intersect(intersect(which((time[i] > time)),
                             which(status!=cause)), which(censor.status==1))] = 1
    #B[i, intersect(intersect(which((time[i] >= time)),
    #                         which(status!=cause)), which(censor.status==1))] = 1
    # Include pairs tied in uncensored event times
    B[i, which(time[i] == time & status == cause & censor.status == 1)] = 1
    # Compare predictions. Including ties. 
    #Q[i, which(predictions[i] >= predictions)] = 1
    Q[i, which(predictions[i] >= predictions)] = 1
  }
  
  for (i in 1:n){
    if(time[i]<=tau && status[i]==cause && censor.status[i]==1){
      N_t[i,] = 1
    }
  }
  
  # Compute numerator and denominator matrices with IPCW weights
  for (i in 1:n) {
    for (j in 1:n) {
      if (i != j) {
        Num_mat[i, j] <- (A[i, j] + B[i, j]) * Q[i, j] * N_t[i, j] * ipcw[i] * ipcw[j]
        Den_mat[i, j] <- (A[i, j] + B[i, j]) * N_t[i, j] * ipcw[i] * ipcw[j]
      }
    }
  }
  
  #Num_mat = (A+B)*Q*N_t
  #Den_mat = (A+B)*N_t
  
  Num = sum(Num_mat)
  Den = sum(Den_mat)
  
  return(Num/Den)
  
}
```



```{r}
#source("CompRisksMetrics/ConcordanceIndex2.R") 

weight.i <- pec::ipcw(formula=
                        Surv(time,censor.status)~1,
                 data=tmp,
                 method="marginal",
                 times=unique(tmp$time),
                 subjectTimes=tmp$time, 
                 what = "IPCW.subjectTimes")$IPCW.subjectTimes

tmp$ipcw_subject_times <- weight.i


# Predicted risk estimation
tmp_pred <- riskRegression::predictRisk(fit_csh,
  cause = primary_event,
  times = horizon,
  newdata = tmp
)


CIndexCRisks2(predictions=tmp_pred,
                          time = tmp$time,
                          cens.code = 0,
                          status=tmp$status,
                          cause= primary_event,
                          ipcw = tmp$ipcw_subject_times,
                          tau=horizon,
                          method = "cifs")

```


```{r}
C_vdata
```

```{r}
source("CompRisksMetrics/ConcordanceIndexMTimes.R") 
```


```{r}
taus <- c(1,3,5) 

# Predicted risk estimation
preds <- predictRisk(fit_csh,
  cause = primary_event,
  times = taus,
  newdata = vdata
)

CIndexCRisksMTimes(predictions=preds,
                          time = vdata$time,
                          cens.code = 0,
                          status=vdata$status,
                          cause= primary_event, 
                          taus=taus,
                          method = "cifs")
```

### Ties 

How to handle ties: 

1) Ties can happen when $\tau_{i} = \tau_{j}$ when two individuals have the same but different outcome. 


2) Ties can happen when the prediction value is the same for both individuals 
the model does not differentiate between individuals i and j in terms of risk ranking.

Approaches: 

- They can still be comparable pairs if one individual experience the event, and the other individual the competing risk.  If both individuals have the same event type and time, they are not considered comparable for concordance.

- These pairs can be treated as "partially concordant", with fractional credit (e.g., 0.5) given for ties.
    \[
    Q_{ij} =
    \begin{cases}
    1, & \text{if } f_i > f_j, \\
    0.5, & \text{if } f_i = f_j, \\
    0, & \text{if } f_i < f_j.
    \end{cases}
    \]

- Tied predicted risks are excluded from the calculation altogether.

- Penalized ties (e.g., $Q_{ij} =0.5−\epsilon$, where \epsilon is a small positive value) to discourage models that frequently produce tied predictions.
\[
    Q_{ij} =
    \begin{cases}
    1, & \text{if } f_i > f_j, \\
    0.5 - \epsilon, & \text{if } f_i = f_j, \\
    0, & \text{if } f_i < f_j.
    \end{cases}
    \]
- Break ties randomly ... assigning randomly 0 or 1 to the Q.



### Next CI 

### Next: How to handle ties

### Next Include AUC. 
